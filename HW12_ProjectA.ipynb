{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-auc:0.847165\tvalid-auc:0.684547\n",
      "Multiple eval metrics have been passed: 'valid-auc' will be used for early stopping.\n",
      "\n",
      "Will train until valid-auc hasn't improved in 200 rounds.\n",
      "[25]\ttrain-auc:0.962632\tvalid-auc:0.760941\n",
      "[50]\ttrain-auc:0.972215\tvalid-auc:0.77431\n",
      "[75]\ttrain-auc:0.986662\tvalid-auc:0.777693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/xgboost/core.py:587: FutureWarning: Series.base is deprecated and will be removed in a future version\n",
      "  if getattr(data, 'base', None) is not None and \\\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[100]\ttrain-auc:0.991351\tvalid-auc:0.776056\n",
      "[125]\ttrain-auc:0.993668\tvalid-auc:0.780967\n",
      "[150]\ttrain-auc:0.995842\tvalid-auc:0.785551\n",
      "[175]\ttrain-auc:0.99762\tvalid-auc:0.78937\n",
      "[200]\ttrain-auc:0.998518\tvalid-auc:0.795154\n",
      "[225]\ttrain-auc:0.999003\tvalid-auc:0.800065\n",
      "[250]\ttrain-auc:0.999299\tvalid-auc:0.802139\n",
      "[275]\ttrain-auc:0.999677\tvalid-auc:0.801266\n",
      "[300]\ttrain-auc:0.999829\tvalid-auc:0.803994\n",
      "[325]\ttrain-auc:0.999919\tvalid-auc:0.803994\n",
      "[350]\ttrain-auc:0.999946\tvalid-auc:0.802794\n",
      "[375]\ttrain-auc:0.999973\tvalid-auc:0.805304\n",
      "[400]\ttrain-auc:0.999982\tvalid-auc:0.807596\n",
      "[425]\ttrain-auc:1\tvalid-auc:0.807814\n",
      "[450]\ttrain-auc:1\tvalid-auc:0.810215\n",
      "[475]\ttrain-auc:1\tvalid-auc:0.811306\n",
      "[500]\ttrain-auc:1\tvalid-auc:0.810761\n",
      "[525]\ttrain-auc:1\tvalid-auc:0.811306\n",
      "[550]\ttrain-auc:1\tvalid-auc:0.811961\n",
      "[575]\ttrain-auc:1\tvalid-auc:0.811415\n",
      "[600]\ttrain-auc:1\tvalid-auc:0.810761\n",
      "[625]\ttrain-auc:1\tvalid-auc:0.811634\n",
      "[650]\ttrain-auc:1\tvalid-auc:0.811743\n",
      "[675]\ttrain-auc:1\tvalid-auc:0.811852\n",
      "[700]\ttrain-auc:1\tvalid-auc:0.811306\n",
      "[725]\ttrain-auc:1\tvalid-auc:0.812507\n",
      "[750]\ttrain-auc:1\tvalid-auc:0.812725\n",
      "[775]\ttrain-auc:1\tvalid-auc:0.81458\n",
      "[800]\ttrain-auc:1\tvalid-auc:0.815453\n",
      "[825]\ttrain-auc:1\tvalid-auc:0.815999\n",
      "[850]\ttrain-auc:1\tvalid-auc:0.815017\n",
      "[875]\ttrain-auc:1\tvalid-auc:0.815999\n",
      "[900]\ttrain-auc:1\tvalid-auc:0.815563\n",
      "[925]\ttrain-auc:1\tvalid-auc:0.815126\n",
      "[950]\ttrain-auc:1\tvalid-auc:0.815781\n",
      "[975]\ttrain-auc:1\tvalid-auc:0.816981\n",
      "[1000]\ttrain-auc:1\tvalid-auc:0.816763\n",
      "[1025]\ttrain-auc:1\tvalid-auc:0.816981\n",
      "[1050]\ttrain-auc:1\tvalid-auc:0.81709\n",
      "[1075]\ttrain-auc:1\tvalid-auc:0.816872\n",
      "[1100]\ttrain-auc:1\tvalid-auc:0.816763\n",
      "[1125]\ttrain-auc:1\tvalid-auc:0.816763\n",
      "[1150]\ttrain-auc:1\tvalid-auc:0.816654\n",
      "[1175]\ttrain-auc:1\tvalid-auc:0.81709\n",
      "[1200]\ttrain-auc:1\tvalid-auc:0.816763\n",
      "[1225]\ttrain-auc:1\tvalid-auc:0.816654\n",
      "Stopping. Best iteration:\n",
      "[1047]\ttrain-auc:1\tvalid-auc:0.817745\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('train.csv',index_col=0)\n",
    "test=pd.read_csv('test.csv',index_col=0)\n",
    "\n",
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())\n",
    "\n",
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "\n",
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#train.to_csv('temp.csv')\n",
    "#print(train)\n",
    "\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "param = {'boosting_type':'gbdt',\n",
    "                         'objective' : 'binary:logistic', #\n",
    "                         'eval_metric' : 'auc',\n",
    "                         'eta' : 0.01,\n",
    "                         'max_depth' : 15,\n",
    "                         'colsample_bytree':0.8,\n",
    "                         'subsample': 0.9,\n",
    "                         'subsample_freq': 8,\n",
    "                         'alpha': 0.6,\n",
    "                         'lambda': 0,\n",
    "        }\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)\n",
    "\n",
    "train_data = xgb.DMatrix(X_train, label=y_train)\n",
    "valid_data = xgb.DMatrix(X_valid, label=y_valid)\n",
    "test_data = xgb.DMatrix(test)\n",
    "\n",
    "model = xgb.train(param, train_data, evals=[(train_data, 'train'), (valid_data, 'valid')], num_boost_round = 10000, early_stopping_rounds=200, verbose_eval=25)\n",
    "predict = model.predict(test_data)\n",
    "test['Attrition']=predict\n",
    "# 转化为二分类输出\n",
    "test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "test[['Attrition']].to_csv('submit_xgb.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 3, 5, 6, 9, 13, 15, 19, 20]\n",
      "0:\ttest: 0.6390374\tbest: 0.6390374 (0)\ttotal: 61.4ms\tremaining: 1m 1s\n",
      "50:\ttest: 0.7998472\tbest: 0.7998472 (50)\ttotal: 413ms\tremaining: 7.68s\n",
      "100:\ttest: 0.8054131\tbest: 0.8054131 (100)\ttotal: 716ms\tremaining: 6.38s\n",
      "150:\ttest: 0.8053039\tbest: 0.8054131 (100)\ttotal: 1.12s\tremaining: 6.32s\n",
      "200:\ttest: 0.8075958\tbest: 0.8075958 (200)\ttotal: 1.55s\tremaining: 6.16s\n",
      "250:\ttest: 0.8062862\tbest: 0.8075958 (200)\ttotal: 2s\tremaining: 5.97s\n",
      "300:\ttest: 0.8045400\tbest: 0.8075958 (200)\ttotal: 2.4s\tremaining: 5.57s\n",
      "350:\ttest: 0.8059587\tbest: 0.8075958 (200)\ttotal: 2.78s\tremaining: 5.13s\n",
      "400:\ttest: 0.8065044\tbest: 0.8075958 (200)\ttotal: 3.18s\tremaining: 4.74s\n",
      "450:\ttest: 0.8065044\tbest: 0.8075958 (200)\ttotal: 3.53s\tremaining: 4.3s\n",
      "500:\ttest: 0.8077049\tbest: 0.8077049 (500)\ttotal: 3.92s\tremaining: 3.91s\n",
      "550:\ttest: 0.8090145\tbest: 0.8090145 (550)\ttotal: 4.28s\tremaining: 3.49s\n",
      "600:\ttest: 0.8106515\tbest: 0.8106515 (600)\ttotal: 4.64s\tremaining: 3.08s\n",
      "650:\ttest: 0.8113063\tbest: 0.8113063 (650)\ttotal: 4.98s\tremaining: 2.67s\n",
      "700:\ttest: 0.8125068\tbest: 0.8125068 (700)\ttotal: 5.31s\tremaining: 2.27s\n",
      "750:\ttest: 0.8126160\tbest: 0.8126160 (750)\ttotal: 5.65s\tremaining: 1.87s\n",
      "800:\ttest: 0.8116337\tbest: 0.8126160 (750)\ttotal: 6.02s\tremaining: 1.5s\n",
      "850:\ttest: 0.8121794\tbest: 0.8126160 (750)\ttotal: 6.47s\tremaining: 1.13s\n",
      "900:\ttest: 0.8116337\tbest: 0.8126160 (750)\ttotal: 7.01s\tremaining: 770ms\n",
      "950:\ttest: 0.8111972\tbest: 0.8126160 (750)\ttotal: 7.5s\tremaining: 387ms\n",
      "999:\ttest: 0.8108698\tbest: 0.8126160 (750)\ttotal: 7.98s\tremaining: 0us\n",
      "\n",
      "bestTest = 0.8126159555\n",
      "bestIteration = 750\n",
      "\n",
      "Shrink model to first 751 iterations.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('train.csv',index_col=0)\n",
    "test=pd.read_csv('test.csv',index_col=0)\n",
    "\n",
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())\n",
    "\n",
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "\n",
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#print(train)\n",
    "\n",
    "import catboost as cb\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)\n",
    "\n",
    "model = cb.CatBoostClassifier(iterations=1000, \n",
    "                              depth=7, \n",
    "                              learning_rate=0.01, \n",
    "                              loss_function='Logloss', \n",
    "                              eval_metric='AUC',\n",
    "                              logging_level='Verbose', \n",
    "                              metric_period=50\n",
    "                             )\n",
    "\n",
    "# 得到分类特征的列号\n",
    "categorical_features_indices = []\n",
    "for i in range(len(X_train.columns)):\n",
    "    if X_train.columns.values[i] in attr:\n",
    "        categorical_features_indices.append(i)\n",
    "print(categorical_features_indices)\n",
    "\n",
    "model.fit(X_train, y_train, eval_set=(X_valid, y_valid), cat_features=categorical_features_indices)\n",
    "\n",
    "#model = cb.train(param, train_data, evals=[(train_data, 'train'), (valid_data, 'valid')], num_boost_round = 10000, early_stopping_rounds=200, verbose_eval=25)\n",
    "predict = model.predict(test)\n",
    "#predict = model.predict_proba(test)\n",
    "#print(predict)\n",
    "test['Attrition']=predict\n",
    "## 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "test[['Attrition']].to_csv('submit_cb.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "dlopen(/opt/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /opt/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-1f08858868e3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;31m#print(train)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m# param = {\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/lightgbm/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0m__future__\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mabsolute_import\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mbasic\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBooster\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m from .callback import (early_stopping, print_evaluation, record_evaluation,\n\u001b[1;32m     10\u001b[0m                        reset_parameter)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 33\u001b[0;31m \u001b[0m_LIB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_load_lib\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m_load_lib\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m     \u001b[0mlib\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcdll\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlib_path\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m     \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLGBM_GetLastError\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrestype\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mctypes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_char_p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36mLoadLibrary\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    441\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mLoadLibrary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 442\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dlltype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    443\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    444\u001b[0m \u001b[0mcdll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLibraryLoader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCDLL\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/ctypes/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode, handle, use_errno, use_last_error)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_dlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: dlopen(/opt/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so, 6): Library not loaded: /usr/local/opt/libomp/lib/libomp.dylib\n  Referenced from: /opt/anaconda3/lib/python3.7/site-packages/lightgbm/lib_lightgbm.so\n  Reason: image not found"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('train.csv',index_col=0)\n",
    "test=pd.read_csv('test.csv',index_col=0)\n",
    "\n",
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())\n",
    "\n",
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "\n",
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#train.to_csv('temp.csv')\n",
    "#print(train)\n",
    "\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "# param = {\n",
    "#     'num_leaves':41,\n",
    "#     'boosting_type': 'gbdt',\n",
    "#     'objective':'binary',\n",
    "#     'max_depth':15,\n",
    "#     'learning_rate':0.001,\n",
    "#     'metric':'binary_logloss'}\n",
    "param = {'boosting_type':'gbdt',\n",
    "                         'objective' : 'binary', #\n",
    "                         #'metric' : 'binary_logloss',\n",
    "                         'metric' : 'auc',\n",
    "#                          'metric' : 'self_metric',\n",
    "                         'learning_rate' : 0.01,\n",
    "                         'max_depth' : 15,\n",
    "                         'feature_fraction':0.8,\n",
    "                         'bagging_fraction': 0.9,\n",
    "                         'bagging_freq': 8,\n",
    "                         'lambda_l1': 0.6,\n",
    "                         'lambda_l2': 0,\n",
    "#                          'scale_pos_weight':k,\n",
    "#                         'is_unbalance':True\n",
    "        }\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)\n",
    "train_data = lgb.Dataset(X_train, label=y_train)\n",
    "valid_data = lgb.Dataset(X_valid, label=y_valid)\n",
    "\n",
    "\n",
    "model = lgb.train(param,train_data,valid_sets=[train_data,valid_data],num_boost_round = 10000 ,early_stopping_rounds=200,verbose_eval=25, categorical_feature=attr)\n",
    "predict=model.predict(test)\n",
    "#print(predict)\n",
    "test['Attrition']=predict\n",
    "test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "#test['Attrition']=predict\n",
    "test[['Attrition']].to_csv('submit_lgb.csv')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iter 0] loss=0.4190 val_loss=0.0000 scale=1.0000 norm=2.0000\n",
      "[iter 50] loss=0.3427 val_loss=0.0000 scale=1.0000 norm=1.7212\n",
      "[iter 100] loss=0.3005 val_loss=0.0000 scale=1.0000 norm=1.6308\n",
      "[iter 150] loss=0.2782 val_loss=0.0000 scale=1.0000 norm=1.5989\n",
      "[iter 200] loss=0.2683 val_loss=0.0000 scale=1.0000 norm=1.5975\n",
      "[iter 250] loss=0.2606 val_loss=0.0000 scale=1.0000 norm=1.5968\n",
      "[iter 300] loss=0.2531 val_loss=0.0000 scale=1.0000 norm=1.5853\n",
      "[iter 350] loss=0.2493 val_loss=0.0000 scale=1.0000 norm=1.5803\n",
      "[iter 400] loss=0.2465 val_loss=0.0000 scale=0.5000 norm=0.7870\n",
      "[iter 450] loss=0.2442 val_loss=0.0000 scale=0.1250 norm=0.1966\n",
      "[iter 500] loss=0.2421 val_loss=0.0000 scale=1.0000 norm=1.5711\n",
      "[iter 550] loss=0.2407 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 600] loss=0.2407 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 650] loss=0.2407 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 700] loss=0.2407 val_loss=0.0000 scale=0.0010 norm=0.0015\n",
      "[iter 750] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 800] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 850] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 900] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n",
      "[iter 950] loss=0.2402 val_loss=0.0000 scale=0.0002 norm=0.0004\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('train.csv',index_col=0)\n",
    "test=pd.read_csv('test.csv',index_col=0)\n",
    "\n",
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())\n",
    "\n",
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "\n",
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#print(train)\n",
    "\n",
    "import ngboost as ng\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)\n",
    "\n",
    "model = ng.NGBClassifier(n_estimators=1000, \n",
    "                              learning_rate=0.01, \n",
    "                              verbose=True, \n",
    "                              verbose_eval=50\n",
    "                             )\n",
    "\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "#predict = model.predict(test)\n",
    "predict = model.predict_proba(test)[:, 1]\n",
    "#print(predict)\n",
    "test['Attrition']=predict\n",
    "## 转化为二分类输出\n",
    "test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "test[['Attrition']].to_csv('submit_ngb.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LibLinear][0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0\n",
      " 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train=pd.read_csv('train.csv',index_col=0)\n",
    "test=test1=pd.read_csv('test.csv',index_col=0)\n",
    "\n",
    "#print(train['Attrition'].value_counts())\n",
    "# 处理Attrition字段\n",
    "train['Attrition']=train['Attrition'].map(lambda x:1 if x=='Yes' else 0)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "# 查看数据是否有空值\n",
    "#print(train.isna().sum())\n",
    "\n",
    "# 去掉没用的列 员工号码，标准工时（=80）\n",
    "train = train.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "test = test.drop(['EmployeeNumber', 'StandardHours'], axis=1)\n",
    "\n",
    "# 对于分类特征进行特征值编码\n",
    "attr=['Age','BusinessTravel','Department','Education','EducationField','Gender','JobRole','MaritalStatus','Over18','OverTime']\n",
    "lbe_list=[]\n",
    "for feature in attr:\n",
    "    lbe=LabelEncoder()\n",
    "    train[feature]=lbe.fit_transform(train[feature])\n",
    "    test[feature]=lbe.transform(test[feature])\n",
    "    lbe_list.append(lbe)\n",
    "#print(train)\n",
    "\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(train.drop('Attrition',axis=1), train['Attrition'], test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "mms = MinMaxScaler(feature_range=(0, 1))\n",
    "X_train = mms.fit_transform(X_train)\n",
    "X_valid = mms.fit_transform(X_valid)\n",
    "test = mms.fit_transform(test)\n",
    "\n",
    "model = SVC(kernel='rbf', \n",
    "\t\t\tgamma=\"auto\",\n",
    "\t\t\tmax_iter=1000,\n",
    "\t\t\trandom_state=33,\n",
    "\t\t\tverbose=True,\n",
    "\t\t\ttol=1e-5,\n",
    "\t\t\tcache_size=50000\n",
    "\t\t   )\n",
    "#print(X_train)\n",
    "#print(y_train)\n",
    "#print(sum(y_train))\n",
    "\n",
    "model = LinearSVC(\n",
    "\t\t\tmax_iter=1000,\n",
    "\t\t\trandom_state=33,\n",
    "\t\t\tverbose=True,\n",
    "\t\t   )\n",
    "model.fit(X_train, y_train)\n",
    "predict = model.predict(test)\n",
    "print(predict)\n",
    "#print(test)\n",
    "#predict = model.predict_proba(test)[:, 1]\n",
    "test1['Attrition']=predict\n",
    "\n",
    "# 转化为二分类输出\n",
    "#test['Attrition']=test['Attrition'].map(lambda x:1 if x>=0.5 else 0)\n",
    "test1[['Attrition']].to_csv('submit_svc.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
